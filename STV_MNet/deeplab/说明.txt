实验用到的数据为deeplearning文件夹
实验代码及修改采用的是csdn上某一位博主的流程，代码是github上的开源项目。https://blog.csdn.net/qq_39056987/article/details/106455828

环境依赖部分：
实验中使用到的是pycharm平台，电脑为英伟达GTX1650，支持CUDA加速，安装部分可详见这里https://blog.csdn.net/chen565884393/article/details/127905428
注意安装前一定要先安装visual studio。pytorch安装如下：https://blog.csdn.net/MCYZSF/article/details/116525159

环境
appdirs                 1.4.4
brotlipy                0.7.0
cachetools              5.3.0
certifi                 2022.12.7
cffi                    1.15.1
charset-normalizer      2.0.4
colorama                0.4.6
contourpy               1.0.5
cryptography            39.0.1
cycler                  0.11.0
filelock                3.9.0
flit_core               3.8.0
fonttools               4.25.0
google-auth             2.17.1
google-auth-oauthlib    1.0.0
grpcio                  1.53.0
idna                    3.4
imgviz                  1.7.2
importlib-metadata      6.1.0
importlib-resources     5.2.0
Jinja2                  3.1.2
kiwisolver              1.4.4
labelme                 3.16.7
Markdown                3.4.3
MarkupSafe              2.1.1
matplotlib              3.7.1
mkl-fft                 1.3.1
mkl-random              1.2.2
mkl-service             2.4.0
mpmath                  1.2.1
munkres                 1.1.4
natsort                 8.3.1
networkx                2.8.4
numpy                   1.23.5
oauthlib                3.2.2
onnx                    1.13.0
opencv-python           4.7.0.72
packaging               23.0
Pillow                  9.4.0
pip                     23.0.1
ply                     3.11
pooch                   1.4.0
protobuf                3.20.3
pyasn1                  0.4.8
pyasn1-modules          0.2.8
pycocotools             2.0.6
pycparser               2.21
pyOpenSSL               23.0.0
pyparsing               3.0.9
PyQt5                   5.15.7
PyQt5-sip               12.11.0
PySocks                 1.7.1
python-dateutil         2.8.2
PyYAML                  6.0
QtPy                    2.3.1
requests                2.28.1
requests-oauthlib       1.3.1
rsa                     4.9
scipy                   1.10.0
setuptools              65.6.3
sip                     6.6.2
six                     1.16.0
sympy                   1.11.1
tensorboard             2.12.1
tensorboard-data-server 0.7.0
tensorboard-plugin-wit  1.8.1
tensorboardX            2.6
termcolor               2.2.0
toml                    0.10.2
torch                   2.0.0
torchaudio              2.0.0
torchvision             0.15.0
tornado                 6.2
tqdm                    4.65.0
typing_extensions       4.4.0
urllib3                 1.26.15
Werkzeug                2.2.3
wheel                   0.38.4
win-inet-pton           1.1.0
wincertstore            0.2
zipp                    3.11.0

预测：python demo.py --in-path E:\new\tao\pytorch-deeplab-xception-master\test\ --out-path E:\new\tao\pytorch-deeplab-xception-master\test\  --ckpt E:\new\tao\pytorch-deeplab-xception-master\run\deeplearning\deeplab-drn\model_best.pth.tar --backbone drn --dataset deeplearning



数据处理部分：
标注完labelme后，将原图和json文件放一个文件夹，即代码中的datasets文件夹下的before文件夹，运行json_to_dataset.py文件，即可得到语义分割标签图，原图在datasets文件夹下的JPEGImages文件夹中，标签在SegmentationClass文件夹中。
将得到的JPEGImages文件夹和SegmentationClass文件夹放入项目中VOCdevkit文件夹中（此文件夹里已经新建好一个ImageSets文件夹并且其内包含Segmentation文件夹），运行voc_annotation.py文件即可划分训练集和验证集以及测试集（比例可以更改，具体代码里有备注，我所使用的项目不使用测试集，验证集当作测试集使用）
如果需要用到数据增强，将图片放入项目中image文件夹下，运行inhance.py文件增强后的文件名字前加了一个T放入image_1文件夹下。不必将原图数据增强之后再来一次labelme标注，直接可以把原图的语义分割标签文件数据增强，亲测效果很好。（这里的数据增强只选用了水平翻转）

addTest.py为将后续实测道路的图像加入到测试集中




